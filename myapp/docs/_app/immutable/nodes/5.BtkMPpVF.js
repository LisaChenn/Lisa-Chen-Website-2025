import{f,a as g}from"../chunks/BYtvtqGt.js";import"../chunks/C7WVXHeY.js";import{U as y,N as w,O as b,V as I,M as d,P as e,Q as t,W as A}from"../chunks/BsH6kw9D.js";import{s as q}from"../chunks/CgfndZMD.js";import{N as _,s as k}from"../chunks/D4ciADiu.js";import{i as S}from"../chunks/BnvqbeGA.js";var O=f(`<!> <main class="wrap svelte-nvo3cq"><article class="post svelte-nvo3cq"><header class="post__header svelte-nvo3cq"><h1 class="post__title svelte-nvo3cq">The Ethics Behind the Use of AI</h1> <p class="post__meta svelte-nvo3cq"><time> </time></p></header> <section class="post__content svelte-nvo3cq"><p class="svelte-nvo3cq">Every day there are new discoveries, published technologies, and developed software—and with them,
          real ethical and humanitarian concerns. Most recently, the use of AI has brought a surge of people
          advocating for its discontinuation for reasons such as environmental costs, human-rights risks, job
          displacement, and data security. Even among engineers—the people who build these systems—opinions are
          divided. Governments worldwide are integrating AI into modern warfare and national security. At the
          same time, netizens with malicious intentions create deepfakes; many are non-consensual and explicit,
          disproportionately targeting women. Meanwhile, AI is becoming routine in everyday life and education: <sup class="svelte-nvo3cq">[1]</sup> 92% of university students report using AI for homework, tests, studying, and email.
          AI is rapidly becoming embedded in every sense of the word. Because of this, the speed of change is
          forcing us to confront not only what these systems can do, but what they should do.</p> <p class="svelte-nvo3cq">Google once had an unofficial motto: “Don’t be evil.” This motto was meant to guide actions and
          decisions; however, in 2025 that changed. In February 2025, <sup class="svelte-nvo3cq">[2]</sup> Google quietly updated its AI
          principles and removed its previous pledge against using its technology for military weapons or
          surveillance. It reached an agreement with the U.S. government and helped implement AI software
          within military systems. Now, people may die at the hands of artificial intelligence rather than a
          human—for the sake of efficiency, convenience, and, most importantly, cost.</p> <p class="svelte-nvo3cq">Is it right or is it wrong? Much of AI’s appeal is convenience—drafting a paper, an email, a
          speech—yet the same convenience can be bent toward harmful ends, including lethal or malicious uses.
          Many worry AI could accelerate social harms and call for limits or moratoria, while others see
          transformative benefits. <sup class="svelte-nvo3cq">[3]</sup> AI can increase efficiency and productivity by automating
          repetitive tasks, improve decision-making with pattern analysis, accelerate R&amp;D through simulation
          and optimization, enhance safety with predictive maintenance and anomaly detection, and broaden
          accessibility via translation and assistive tools. So what is the right call? What should we do with
          AI’s development?</p> <p class="svelte-nvo3cq">Personally, I believe responsible AI use ultimately comes down to education—education on how to use
          AI, how to verify its outputs, and when not to use it. We need to reinforce that AI is a tool, not a
          replacement for a human. It’s important to know when not to use AI: in high-stakes contexts without
          human oversight, where data consent is unclear, or where using AI would undermine learning or
          professional standards. With that foundation, AI becomes less a shortcut and more a disciplined
          instrument that augments human judgment. Additionally, lawmakers should ban the creation of deepfakes
          and harmful AI-generated videos to curb misinformation and defamation. As for AI embedded in military
          platforms, I have no definitive stance. It can save lives and it can take lives; there isn’t yet
          enough public evidence to reach a firm conclusion.</p></section> <footer class="post__footer svelte-nvo3cq"><h2 class="visually-hidden svelte-nvo3cq">References</h2> <ol class="refs svelte-nvo3cq"><li id="ref-1">[1] Campbell Academic Technology Services, “AI in Higher Education: A Meta Summary of Recent Surveys of Students and Faculty,” Mar. 6, 2025. [Online]. Available: https://sites.campbell.edu/academictechnology/2025/03/06/ai-in-higher-education-a-summary-of-recent-surveys-of-students-and-faculty/. Accessed: Oct. 5, 2025. Campbell Sites</li> <li id="ref-2">[2] P. Dave and C. Haskins, “Google Lifts a Ban on Using Its AI for Weapons and Surveillance,” WIRED, Feb. 4, 2025. [Online]. Available: https://www.wired.com/story/google-responsible-ai-principles/. Accessed: Oct. 5, 2025. WIRED</li> <li id="ref-3">[3] University of Cincinnati Online, “9 Benefits of Artificial Intelligence (AI) in 2025.” [Online]. Available: https://online.uc.edu/blog/artificial-intelligence-ai-benefits/. Accessed: Oct. 5, 2025. University of Cincinnati</li></ol></footer></article></main>`,1);function C(h,m){y(m,!1);const n=new Date("2025-10-05"),p=new Intl.DateTimeFormat("en-US",{dateStyle:"long"}).format(n);S();var i=O(),s=w(i);_(s,{});var o=d(s,2),r=e(o),l=e(r),c=d(e(l),2),a=e(c),u=e(a,!0);t(a),t(c),t(l),A(4),t(r),t(o),b(v=>{k(a,"datetime",v),q(u,p)},[()=>n.toISOString()]),g(h,i),I()}export{C as component};
